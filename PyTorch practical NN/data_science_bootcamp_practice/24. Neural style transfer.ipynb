{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-04T15:42:11.878502300Z",
     "start_time": "2023-07-04T15:42:07.324753400Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models,transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def get_image(path, img_transform, size = (300,300)):\n",
    "    image = Image.open(path)\n",
    "    image = image.resize(size, Image.LANCZOS)\n",
    "    image = img_transform(image).unsqueeze(0)\n",
    "    return image.to(device)\n",
    "\n",
    "def get_gram(m):\n",
    "    _, c, h, w = m.size()\n",
    "    m = m.view(c, h * w)\n",
    "    m = torch.mm(m, m.t())\n",
    "    return m\n",
    "\n",
    "def denormalize_img(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T03:57:06.663456900Z",
     "start_time": "2023-07-05T03:57:06.618474300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.selected_layers = [3, 8, 15, 22]\n",
    "        self.vgg = models.vgg16(pretrained=True).features\n",
    "\n",
    "    def forward(self, x):\n",
    "        layer_features = []\n",
    "        for layer_number, layer in self.vgg._modules.items():\n",
    "            x = layer(x)\n",
    "            if int(layer_number) in self.selected_layers:\n",
    "                layer_features.append(x)\n",
    "        return layer_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T03:57:07.208748400Z",
     "start_time": "2023-07-05T03:57:07.178663600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mi\\.conda\\envs\\conda_default_env_backup\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mi\\.conda\\envs\\conda_default_env_backup\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "img_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "content_img = get_image('content.jpg', img_transform)\n",
    "style_img = get_image('style.jpg', img_transform)\n",
    "generated_img = content_img.clone()    # or nn.Parameter(torch.FloatTensor(content_img.size()))\n",
    "generated_img.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam([generated_img], lr=0.003, betas=[0.5, 0.999])\n",
    "encoder = FeatureExtractor().to(device)\n",
    "\n",
    "for p in encoder.parameters():\n",
    "    p.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T03:57:31.777145600Z",
     "start_time": "2023-07-05T03:57:29.547376Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\tContent Loss: 0.0000\tStyle Loss: 6196.9077\n",
      "Epoch [10]\tContent Loss: 0.4555\tStyle Loss: 5835.3252\n",
      "Epoch [20]\tContent Loss: 0.8173\tStyle Loss: 5372.0059\n",
      "Epoch [30]\tContent Loss: 1.0521\tStyle Loss: 4937.8672\n",
      "Epoch [40]\tContent Loss: 1.1999\tStyle Loss: 4553.6685\n",
      "Epoch [50]\tContent Loss: 1.3045\tStyle Loss: 4184.9644\n",
      "Epoch [60]\tContent Loss: 1.3787\tStyle Loss: 3818.4541\n",
      "Epoch [70]\tContent Loss: 1.4327\tStyle Loss: 3457.6013\n",
      "Epoch [80]\tContent Loss: 1.4767\tStyle Loss: 3109.7593\n",
      "Epoch [90]\tContent Loss: 1.5154\tStyle Loss: 2784.1450\n",
      "Epoch [100]\tContent Loss: 1.5485\tStyle Loss: 2489.3018\n",
      "Epoch [110]\tContent Loss: 1.5781\tStyle Loss: 2231.2903\n",
      "Epoch [120]\tContent Loss: 1.6065\tStyle Loss: 2011.9043\n",
      "Epoch [130]\tContent Loss: 1.6374\tStyle Loss: 1828.3248\n",
      "Epoch [140]\tContent Loss: 1.6700\tStyle Loss: 1674.6689\n",
      "Epoch [150]\tContent Loss: 1.7030\tStyle Loss: 1544.1252\n",
      "Epoch [160]\tContent Loss: 1.7339\tStyle Loss: 1430.4858\n",
      "Epoch [170]\tContent Loss: 1.7657\tStyle Loss: 1328.8231\n",
      "Epoch [180]\tContent Loss: 1.7974\tStyle Loss: 1235.6715\n",
      "Epoch [190]\tContent Loss: 1.8289\tStyle Loss: 1148.8182\n",
      "Epoch [200]\tContent Loss: 1.8589\tStyle Loss: 1067.1147\n",
      "Epoch [210]\tContent Loss: 1.8878\tStyle Loss: 990.3151\n",
      "Epoch [220]\tContent Loss: 1.9166\tStyle Loss: 918.6124\n",
      "Epoch [230]\tContent Loss: 1.9457\tStyle Loss: 852.3110\n",
      "Epoch [240]\tContent Loss: 1.9731\tStyle Loss: 791.5979\n",
      "Epoch [250]\tContent Loss: 2.0005\tStyle Loss: 736.5838\n",
      "Epoch [260]\tContent Loss: 2.0265\tStyle Loss: 687.2947\n",
      "Epoch [270]\tContent Loss: 2.0515\tStyle Loss: 643.5733\n",
      "Epoch [280]\tContent Loss: 2.0753\tStyle Loss: 605.0823\n",
      "Epoch [290]\tContent Loss: 2.0982\tStyle Loss: 571.2845\n",
      "Epoch [300]\tContent Loss: 2.1201\tStyle Loss: 541.6464\n",
      "Epoch [310]\tContent Loss: 2.1420\tStyle Loss: 515.6610\n",
      "Epoch [320]\tContent Loss: 2.1628\tStyle Loss: 492.7491\n",
      "Epoch [330]\tContent Loss: 2.1830\tStyle Loss: 472.4420\n",
      "Epoch [340]\tContent Loss: 2.2015\tStyle Loss: 454.3092\n",
      "Epoch [350]\tContent Loss: 2.2195\tStyle Loss: 437.9687\n",
      "Epoch [360]\tContent Loss: 2.2366\tStyle Loss: 423.1057\n",
      "Epoch [370]\tContent Loss: 2.2520\tStyle Loss: 409.4507\n",
      "Epoch [380]\tContent Loss: 2.2665\tStyle Loss: 396.7998\n",
      "Epoch [390]\tContent Loss: 2.2812\tStyle Loss: 384.9943\n",
      "Epoch [400]\tContent Loss: 2.2956\tStyle Loss: 373.9155\n",
      "Epoch [410]\tContent Loss: 2.3101\tStyle Loss: 363.4798\n",
      "Epoch [420]\tContent Loss: 2.3233\tStyle Loss: 353.6059\n",
      "Epoch [430]\tContent Loss: 2.3361\tStyle Loss: 344.2176\n",
      "Epoch [440]\tContent Loss: 2.3484\tStyle Loss: 335.2784\n",
      "Epoch [450]\tContent Loss: 2.3603\tStyle Loss: 326.7576\n",
      "Epoch [460]\tContent Loss: 2.3726\tStyle Loss: 318.6113\n",
      "Epoch [470]\tContent Loss: 2.3845\tStyle Loss: 310.8080\n",
      "Epoch [480]\tContent Loss: 2.3962\tStyle Loss: 303.3311\n",
      "Epoch [490]\tContent Loss: 2.4079\tStyle Loss: 296.1703\n"
     ]
    }
   ],
   "source": [
    "content_weight=1\n",
    "style_weight=100\n",
    "epochs=500\n",
    "\n",
    "for epoch in epochs:\n",
    "    content_features=encoder(content_img)\n",
    "    style_features=encoder(style_img)\n",
    "    generated_features = encoder(generated_img)\n",
    "\n",
    "    content_loss=torch.mean((content_features[-1]-generated_features[-1])**2)\n",
    "    style_loss =0\n",
    "    for gf,sf in zip(generated_features,style_features):\n",
    "        _,c,h,w=gf.size()\n",
    "        gram_gf = get_gram(gf)\n",
    "        gram_sf=get_gram(sf)\n",
    "        style_loss+=torch.mean((gram_gf - gram_sf)**2)/(c*h*w)\n",
    "\n",
    "    loss=content_weight * content_loss +style_weight*style_loss\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 ==0:\n",
    "        print('Epoch [{}/{}]\\tContent Loss: {:.4f}\\tStyle Loss: {:.4f}'.format(epoch,epochs,content_loss.item(),style_loss.item()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T04:08:19.019473700Z",
     "start_time": "2023-07-05T03:57:38.158169500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
