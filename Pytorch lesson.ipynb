{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f7c4fd-06a9-4a5e-8e85-4baf9b6fd30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312e968d-c710-4fec-94dd-cc78885954ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([2,2,1])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5708dd7b-9e8c-45b8-b2b1-2ab916fcdd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 1, 4],\n",
      "        [3, 5, 4],\n",
      "        [1, 2, 0],\n",
      "        [4, 3, 2]])\n"
     ]
    }
   ],
   "source": [
    "b=torch.tensor([[2,1,4],[3,5,4],[1,2,0],[4,3,2]])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf3b845f-1b2b-4954-a45f-deef4b6c664d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([3])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(a.size())\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b832b458-6722-4513-b5d9-91b1340b1310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 1., 4.],\n",
      "        [3., 5., 4.],\n",
      "        [1., 2., 0.],\n",
      "        [4., 3., 2.]])\n"
     ]
    }
   ],
   "source": [
    "c=torch.FloatTensor([[2,1,4],[3,5,4],[1,2,0],[4,3,2]])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c7a2f04-1988-470e-9d16-abcc0aa427f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 1., 4.],\n",
      "        [3., 5., 4.],\n",
      "        [1., 2., 0.],\n",
      "        [4., 3., 2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "d=torch.DoubleTensor([[2,1,4],[3,5,4],[1,2,0],[4,3,2]])\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "436142e5-f54e-4640-b190-93a01b18b16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5833)\n"
     ]
    }
   ],
   "source": [
    "print(c.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d499d67-a3e8-4cf1-90e2-10ba8bc4f4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5833, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(d.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68272741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5050)\n"
     ]
    }
   ],
   "source": [
    "print(c.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92e7c6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5050, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(d.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "886da237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [1],\n",
      "        [4],\n",
      "        [3],\n",
      "        [5],\n",
      "        [4],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [4],\n",
      "        [3],\n",
      "        [2]])\n",
      "tensor([2, 1, 4, 3, 5, 4, 1, 2, 0, 4, 3, 2])\n",
      "tensor([[2, 1, 4, 3],\n",
      "        [5, 4, 1, 2],\n",
      "        [0, 4, 3, 2]])\n",
      "tensor([[2, 1, 4, 3],\n",
      "        [5, 4, 1, 2],\n",
      "        [0, 4, 3, 2]])\n",
      "tensor([[2, 1, 4, 3, 5, 4, 1, 2, 0, 4, 3, 2]])\n",
      "torch.Size([1, 12])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tensor([[[-0.3801, -0.5721,  0.7882,  0.1223],\n",
      "         [ 1.3892,  0.1558, -0.2304, -0.3893],\n",
      "         [ 1.5075,  0.7649, -0.3983,  0.5905]],\n",
      "\n",
      "        [[ 0.9012, -0.3783,  1.1543, -0.8194],\n",
      "         [ 1.3427,  1.4874,  0.6196, -2.2705],\n",
      "         [-0.1457, -0.2628, -2.0472, -0.5368]]])\n",
      "tensor([[-0.3801, -0.5721,  0.7882,  0.1223,  1.3892,  0.1558, -0.2304, -0.3893,\n",
      "          1.5075,  0.7649, -0.3983,  0.5905],\n",
      "        [ 0.9012, -0.3783,  1.1543, -0.8194,  1.3427,  1.4874,  0.6196, -2.2705,\n",
      "         -0.1457, -0.2628, -2.0472, -0.5368]])\n",
      "tensor([[-0.3801, -0.5721,  0.7882,  0.1223,  1.3892,  0.1558, -0.2304, -0.3893,\n",
      "          1.5075,  0.7649, -0.3983,  0.5905],\n",
      "        [ 0.9012, -0.3783,  1.1543, -0.8194,  1.3427,  1.4874,  0.6196, -2.2705,\n",
      "         -0.1457, -0.2628, -2.0472, -0.5368]])\n"
     ]
    }
   ],
   "source": [
    "# Reshape b\n",
    "#Note: if one of the dimentions is -1 its size can be inferred\n",
    "print(b.view(-1,1))\n",
    "print(b.view(12))\n",
    "print(b.view(-1,4))\n",
    "print(b.view(3,4))\n",
    "#Assign b a new shape\n",
    "b=b.view(1,-1)\n",
    "print(b)\n",
    "print(b.shape)\n",
    "#we can even reshape 3d tensors\n",
    "print('\\n')\n",
    "#Create a 3d Tensor with 2 channels,3 rows,and 4 columns \n",
    "three_dim=torch.randn(2,3,4)\n",
    "print('\\n')\n",
    "print(three_dim)\n",
    "print(three_dim.view(2,12))\n",
    "print(three_dim.view(2,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5b34b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0152, 0.6753, 0.3068, 0.9674],\n",
      "        [0.9687, 0.7579, 0.5182, 0.6318],\n",
      "        [0.2081, 0.0592, 0.5473, 0.5452],\n",
      "        [0.6891, 0.3897, 0.8718, 0.9356]])\n"
     ]
    }
   ],
   "source": [
    "#Create a matrix with random numbers betwoon 0 and 1\n",
    "r=torch.rand(4,4)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68848c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1201, 0.1442, 0.6448, 0.8497],\n",
      "        [0.8339, 0.1152, 0.5614, 0.3465],\n",
      "        [0.1192, 0.1165, 0.3698, 0.8054],\n",
      "        [0.4384, 0.2038, 0.2756, 0.6921]])\n",
      "<built-in method type of Tensor object at 0x000001EAEAE9CCC0>\n"
     ]
    }
   ],
   "source": [
    "#Create a matrix with random numbers taken from a normal distribution with mean 0 and variance 1\n",
    "r2=torch.rand(4,4)\n",
    "print(r2)\n",
    "print(r2.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "136fefc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 6, 7, 8, 9])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "#create an array of 5 random integers from values between 6 and 9 (exclusive of 10)\n",
    "in_array= torch.randint(6,10,(5,))\n",
    "print(in_array)\n",
    "print(in_array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44fa95e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 9, 6],\n",
      "        [9, 7, 8],\n",
      "        [6, 7, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 2-d array (of matrix) of size 3x3 filled with random integers from values betwoon 6 and 9 (exclosive of 10)\n",
    "in_array2=torch.randint(6,10,(3,3))\n",
    "print(in_array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cade901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#get the number of elements in in_array\n",
    "print(torch.numel(in_array))\n",
    "#get the number of elemnts in in_array2\n",
    "print(torch.numel(in_array2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "861a4d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "#Construc a 3x3 matrix of zeroes and of dtype Long:\n",
    "z=torch.zeros(3,3,dtype=torch.long)\n",
    "print(z)\n",
    "#construct a 3x3 matrix of ones\n",
    "o= torch.ones(3,3)\n",
    "print(o)\n",
    "print(o.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a8b8b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0267,  1.3016,  0.6365,  0.5622],\n",
      "        [ 0.8673, -0.4803,  0.1147, -1.2867],\n",
      "        [-0.8712, -0.6863, -0.6766, -1.5945],\n",
      "        [ 0.8821,  0.3625, -1.1661, -1.1103]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "r2_like=torch.randn_like(r2,dtype=torch.double)\n",
    "print(r2_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fab89e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1353, 0.8195, 0.9516, 1.8170],\n",
      "        [1.8025, 0.8732, 1.0796, 0.9783],\n",
      "        [0.3272, 0.1758, 0.9171, 1.3506],\n",
      "        [1.1275, 0.5934, 1.1473, 1.6277]])\n"
     ]
    }
   ],
   "source": [
    "#add two tensors, maeke sure they are the same size and data type\n",
    "add_result=torch.add(r,r2)\n",
    "print(add_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93be3ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1201, 0.1442, 0.6448, 0.8497],\n",
      "        [0.8339, 0.1152, 0.5614, 0.3465],\n",
      "        [0.1192, 0.1165, 0.3698, 0.8054],\n",
      "        [0.4384, 0.2038, 0.2756, 0.6921]])\n"
     ]
    }
   ],
   "source": [
    "# in place additionn (change the value of r2)\n",
    "r2.add(r)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0eabe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1442, 0.1152, 0.1165, 0.2038])\n",
      "tensor([[0.1201, 0.1442],\n",
      "        [0.8339, 0.1152],\n",
      "        [0.1192, 0.1165],\n",
      "        [0.4384, 0.2038]])\n",
      "tensor([[0.1201, 0.1442, 0.6448, 0.8497],\n",
      "        [0.8339, 0.1152, 0.5614, 0.3465],\n",
      "        [0.1192, 0.1165, 0.3698, 0.8054]])\n",
      "tensor(0.8054)\n",
      "0.8054125905036926\n",
      "tensor([0.1192, 0.1165, 0.3698, 0.8054])\n"
     ]
    }
   ],
   "source": [
    "print(r2[:,1])\n",
    "print(r2[:,:2])\n",
    "print(r2[:3,:])\n",
    "num_ten=r2[2,3]\n",
    "print(num_ten)\n",
    "print(num_ten.item())\n",
    "print(r2[2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e752b95",
   "metadata": {},
   "source": [
    "# Numpy Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11f2f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "280bf3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "#Converting a Torch tensor to a Numpy array\n",
    "a=torch.ones(5)\n",
    "print(a)\n",
    "b=a.numpy()\n",
    "print(b)\n",
    "#see how the numpy array changed their value\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccecf887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#Converting Numpy array to Torch Tensor\n",
    "#See how changing the np array changed the Torch Tensor automatically\n",
    "a=np.ones(5)\n",
    "b=torch.from_numpy(a)\n",
    "np.add(a,1,out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24f86c54",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Move the tensor to the GPU\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m r2\u001b[38;5;241m=\u001b[39m\u001b[43mr2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(r2)\n",
      "File \u001b[1;32mC:\\anaconda\\lib\\site-packages\\torch\\cuda\\__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "#Move the tensor to the GPU\n",
    "r2=r2.cuda()\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25a6127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#provide easy switching between CPU and GPU\n",
    "CUDA=torch.cuda.is_available()\n",
    "print(CUDA)\n",
    "if CUDA:\n",
    "    add_result=add_result.cuda()\n",
    "    print(add_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc8422c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "data=[[1.,2.],[3,4.],[5.,6.],[7.,8.]]\n",
    "T=torch.tensor(data)\n",
    "print(T,T.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f62ef87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3690,  0.9795, -0.7149,  0.1343, -1.4367],\n",
      "        [-0.7619,  0.2167,  0.7678, -0.2433, -0.9056]])\n",
      "tensor([[-0.7192, -0.6598, -0.3239,  0.6584,  1.2669],\n",
      "        [-0.2534,  1.1116, -0.0374, -1.5747,  0.3073],\n",
      "        [-0.3332,  0.8844,  0.0758,  1.6789, -0.8085]])\n",
      "\n",
      "\n",
      "tensor([[-0.3690,  0.9795, -0.7149,  0.1343, -1.4367],\n",
      "        [-0.7619,  0.2167,  0.7678, -0.2433, -0.9056],\n",
      "        [-0.7192, -0.6598, -0.3239,  0.6584,  1.2669],\n",
      "        [-0.2534,  1.1116, -0.0374, -1.5747,  0.3073],\n",
      "        [-0.3332,  0.8844,  0.0758,  1.6789, -0.8085]])\n",
      "\n",
      "\n",
      "tensor([[-1.1714,  0.1896,  1.1623],\n",
      "        [ 0.2524,  1.3178, -0.7994]])\n",
      "tensor([[-0.3486, -2.3121,  0.4427, -0.0500, -0.4535],\n",
      "        [ 1.3297,  0.2050, -1.3135, -1.1241, -0.4722]])\n",
      "\n",
      "\n",
      "tensor([[-1.1714,  0.1896,  1.1623, -0.3486, -2.3121,  0.4427, -0.0500, -0.4535],\n",
      "        [ 0.2524,  1.3178, -0.7994,  1.3297,  0.2050, -1.3135, -1.1241, -0.4722]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tensor Concatenation\n",
    "first_1 = torch.randn(2,5)\n",
    "print(first_1)\n",
    "second_1=torch.randn(3,5)\n",
    "print(second_1)\n",
    "#Concatenate along the 0 dimension (concatenate rows)\n",
    "con_1=torch.cat([first_1,second_1])\n",
    "print('\\n')\n",
    "print(con_1)\n",
    "print('\\n')\n",
    "first_2=torch.randn(2,3)\n",
    "print(first_2)\n",
    "second_2=torch.randn(2,5)\n",
    "print(second_2)\n",
    "#Concatenate along the 1 dimension (concatenate columns)\n",
    "con_2=torch.cat([first_2,second_2],1)\n",
    "print('\\n')\n",
    "print(con_2)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2d5d96",
   "metadata": {},
   "source": [
    "# Adding Dimensions to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00a4ab80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4]])\n",
      "torch.Size([1, 4])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "torch.Size([4, 1])\n",
      "\n",
      "\n",
      "tensor([[[0.9507, 0.8474, 0.0456, 0.2727],\n",
      "         [0.9399, 0.6040, 0.9175, 0.1754],\n",
      "         [0.5283, 0.6604, 0.3022, 0.6991]],\n",
      "\n",
      "        [[0.6199, 0.8866, 0.8614, 0.8308],\n",
      "         [0.6554, 0.4696, 0.2574, 0.3148],\n",
      "         [0.5125, 0.2214, 0.1298, 0.1707]]])\n",
      "\n",
      "\n",
      "tensor([[0.0456, 0.9175, 0.3022],\n",
      "        [0.8614, 0.2574, 0.1298]])\n",
      "torch.Size([2, 3])\n",
      "\n",
      "\n",
      "tensor([[[0.0456],\n",
      "         [0.9175],\n",
      "         [0.3022]],\n",
      "\n",
      "        [[0.8614],\n",
      "         [0.2574],\n",
      "         [0.1298]]])\n",
      "torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "tensor_1=torch.tensor([1,2,3,4])\n",
    "tensor_a=torch.unsqueeze(tensor_1,0)\n",
    "print(tensor_a)\n",
    "print(tensor_a.shape)\n",
    "tensor_b=torch.unsqueeze(tensor_1,1)\n",
    "print(tensor_b)\n",
    "print(tensor_b.shape)\n",
    "print('\\n')\n",
    "tensor_2=torch.rand(2,3,4)\n",
    "print(tensor_2)\n",
    "print('\\n')\n",
    "tensor_c=tensor_2[:,:,2]\n",
    "print(tensor_c)\n",
    "print(tensor_c.shape)\n",
    "print('\\n')\n",
    "tensor_d=torch.unsqueeze(tensor_c,2)\n",
    "print(tensor_d)\n",
    "print(tensor_d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16216edb",
   "metadata": {},
   "source": [
    "# AutoGrad (automaic differentiation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7637d5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x000001EAEAEC8640>\n",
      "tensor(21., grad_fn=<SumBackward0>)\n",
      "<SumBackward0 object at 0x000001EAEAAD9990>\n"
     ]
    }
   ],
   "source": [
    "# If requires_grad=True,the Tensor object keeps track of how it was created.\n",
    "x=torch.tensor([1.,2.,3],requires_grad=True)\n",
    "y=torch.tensor([4.,5.,6],requires_grad=True)\n",
    "#Both x and y have their requirede_grad se to true, therefore we can compute gradients with respect to them\n",
    "z=x+y\n",
    "print(z)\n",
    "# z knows that it was create as a result of addition of x and y. it knows that it wasnt read in from a file\n",
    "print(z.grad_fn)\n",
    "# And we go further on this\n",
    "s=z.sum()\n",
    "print(s)\n",
    "print(s.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60a68f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Now if we backpropogate on s, we can find gradients of s with respect to x\n",
    "s.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba7249ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n",
      "None\n",
      "<AddBackward0 object at 0x000001EAECD0CB80>\n",
      "True\n",
      "None\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#By default, Tensors have `requres_grad=False`\n",
    "x=torch.randn(2,2)\n",
    "y=torch.randn(2,2)\n",
    "print(x.requires_grad,y.requires_grad)\n",
    "z=x+y\n",
    "#so you cant backprop through z\n",
    "print(z.grad_fn)\n",
    "#Another way to set the requires_grad=True is\n",
    "x.requires_grad_()\n",
    "y.requires_grad_()\n",
    "# z contains enough information to compute gradients,as we saw above\n",
    "z=x+y\n",
    "print(z.grad_fn)\n",
    "# If any input to an operation has ``requires_grad=True``, so will the output\n",
    "print(z.requires_grad)\n",
    "# Now z has the computation history that relates itself to x and y\n",
    "\n",
    "new_z=z.detach()\n",
    "print(new_z.grad_fn)\n",
    "# z.detach() returns a tensor that shares the same storage as ``z``,but with the computation history forgotten.\n",
    "# it doesnt know anyting about how it was computed in other wordsm we have broken the Tensor away from its past history\n",
    "\n",
    "# You can also stop autograd from tracking history on Tensors. This concept is useful when applying Transfer Learning \n",
    "print(x.requires_grad)\n",
    "print((x+10).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x+10).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d23d9b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x000001EAEC600B20>\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n",
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "x= torch.ones(2,2,requires_grad=True)\n",
    "print(x)\n",
    "y=x+2\n",
    "print(y)\n",
    "print(y.grad_fn)\n",
    "z=y*y*3\n",
    "out=z.mean()\n",
    "print(z,out)\n",
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463365c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss functions!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
